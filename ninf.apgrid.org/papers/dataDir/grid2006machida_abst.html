<h1> Abstract </h1>
<hr>
Existing data grid scheduling systems handle huge data I/O via replica location services coupled with simple staging,decoupled from scheduling of computing tasks. However,when the application/workflow scales, we observe considerabledegradations in performance, compared to processing withina tightly-coupled cluster. For example, when numerous nodesaccess the same set of files simultaneously, major performancedegradation occurs even if replicas are used, due to bottlenecksthat manifest in the infrastructure. Instead of resorting toexpensive solutions such as parallel file systems, we proposealleviating the situation by tightly coupling replica and datatransfer management with computation scheduling. In particularwe propose three techniques: (1) dynamic aggregation and O(1)replication of data-staging requests across multiple nodes usinga multi-replication framework, (2) replica-centric scheduling ?data re-use and time-to-replication as compute scheduling metricson the grid and (3) overlapped execution of data staging andcompute bound tasks. Early benchmark results implemented inour prototype Condor-like grid scheduling system demonstratethat the techniques are quite effective in eliminating much of theoverhead in data transfers in many cases.
<hr>
